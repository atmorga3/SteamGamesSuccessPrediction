{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AppID' 'Name' 'Release date' 'Estimated owners' 'Peak CCU'\n",
      " 'Required age' 'Price' 'DLC count' 'About the game' 'Supported languages'\n",
      " 'Full audio languages' 'Reviews' 'Header image' 'Website' 'Support url'\n",
      " 'Support email' 'Windows' 'Mac' 'Linux' 'Metacritic score'\n",
      " 'Metacritic url' 'User score' 'Positive' 'Negative' 'Score rank'\n",
      " 'Achievements' 'Recommendations' 'Notes' 'Average playtime forever'\n",
      " 'Average playtime two weeks' 'Median playtime forever'\n",
      " 'Median playtime two weeks' 'Developers' 'Publishers' 'Categories'\n",
      " 'Genres' 'Tags' 'Screenshots' 'Movies']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Data/games.csv')\n",
    "df = pd.DataFrame(data)\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sentiment = SentimentIntensityAnalyzer()\n",
    "\n",
    "df['Review_pos'] = ''\n",
    "df['Review_neu'] = ''\n",
    "df['Review_neg'] = ''\n",
    "\n",
    "for i in range(len(df['Reviews'])):\n",
    "    if pd.isnull(df['Reviews'][i]):\n",
    "        continue\n",
    "    else:\n",
    "        df.loc[i, 'Review_pos'] = sentiment.polarity_scores(df['Reviews'][i])[\"pos\"]\n",
    "        df.loc[i, 'Review_neu'] = sentiment.polarity_scores(df['Reviews'][i])[\"neu\"]\n",
    "        df.loc[i, 'Review_neg'] = sentiment.polarity_scores(df['Reviews'][i])[\"neg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         \n",
       "1         \n",
       "2         \n",
       "3         \n",
       "4         \n",
       "        ..\n",
       "71711     \n",
       "71712     \n",
       "71713     \n",
       "71714     \n",
       "71715     \n",
       "Name: Review_pos, Length: 71716, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "1       NaN\n",
       "2       NaN\n",
       "3       NaN\n",
       "4       NaN\n",
       "         ..\n",
       "71711   NaN\n",
       "71712   NaN\n",
       "71713   NaN\n",
       "71714   NaN\n",
       "71715   NaN\n",
       "Name: Review_neu, Length: 71716, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review_neu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "1       NaN\n",
       "2       NaN\n",
       "3       NaN\n",
       "4       NaN\n",
       "         ..\n",
       "71711   NaN\n",
       "71712   NaN\n",
       "71713   NaN\n",
       "71714   NaN\n",
       "71715   NaN\n",
       "Name: Review_neg, Length: 71716, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review_neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        https://www.metacritic.com/game/galactic-bowling/\n",
       "1            https://www.metacritic.com/game/train-bandit/\n",
       "2            https://www.metacritic.com/game/jolt-project/\n",
       "3                https://www.metacritic.com/game/henosisâ„¢/\n",
       "4        https://www.metacritic.com/game/two-weeks-in-p...\n",
       "                               ...                        \n",
       "71711                https://www.metacritic.com/game/sur5/\n",
       "71712       https://www.metacritic.com/game/prison-life-2/\n",
       "71713    https://www.metacritic.com/game/architecture-z...\n",
       "71714    https://www.metacritic.com/game/girl's-way-to-...\n",
       "71715        https://www.metacritic.com/game/hentai-ariel/\n",
       "Name: Links, Length: 71716, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Links'] = ''\n",
    "\n",
    "for i in range(len(df['Name'])):\n",
    "    temp = str(df['Name'][i]).replace(' ', '-')\n",
    "    temp = 'https://www.metacritic.com/game/' + temp.lower() + '/'\n",
    "    df.loc[i, 'Links'] = temp\n",
    "\n",
    "df['Links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.metacritic.com/game/switch/pokemon-sword/user-reviews?page=0'\n",
    "url = df['Links'][0]\n",
    "\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "response = requests.get(url, headers = user_agent)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.metacritic.com/game/galactic-bowling/\n",
      "[<span data-v-4cdca868=\"\">tbd</span>]\n",
      "tbd\n"
     ]
    }
   ],
   "source": [
    "# soup\n",
    "print(url)\n",
    "spans = soup.find('div', class_='c-siteReviewScore_background c-siteReviewScore_background-critic_medium').find_all('span')\n",
    "print(spans)\n",
    "\n",
    "def find_between( s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "\n",
    "print(find_between(str(spans[0]), \">\", \"</\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinks\u001b[39m\u001b[38;5;124m'\u001b[39m][i], headers \u001b[38;5;241m=\u001b[39m user_agent)\n\u001b[0;32m      7\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     spans \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc-siteReviewScore_background c-siteReviewScore_background-critic_medium\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmscores\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m find_between(\u001b[38;5;28mstr\u001b[39m(spans[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</\u001b[39m\u001b[38;5;124m\"\u001b[39m )\n\u001b[0;32m     11\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmscores\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "df['mscores'] = ''\n",
    "\n",
    "for i in range(len(df['Links'])):\n",
    "    user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(df['Links'][i], headers = user_agent)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    try:\n",
    "        spans = soup.find('div', class_='c-siteReviewScore_background c-siteReviewScore_background-critic_medium').find_all('span')\n",
    "    except:\n",
    "        spans = ['']\n",
    "    df.loc[i, 'mscores'] = find_between(str(spans[0]), \">\", \"</\" )\n",
    "\n",
    "df['mscores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dict = {'name':[], 'date':[], 'rating':[], 'review':[]}\n",
    "\n",
    "for page in range(0,23): #Remember to update the number of pages \n",
    "    url = 'https://www.metacritic.com/game/switch/pokemon-sword/user-reviews?page='+str(page)\n",
    "    user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "    response  = requests.get(url, headers = user_agent)\n",
    "    #time.sleep(rand.randint(3,30)) \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    for review in soup.find_all('div', class_='review_content'):\n",
    "        if review.find('div', class_='name') == None:\n",
    "                       break \n",
    "        review_dict['name'].append(review.find('div', class_='name').find('a').text)\n",
    "        review_dict['date'].append(review.find('div', class_='date').text)\n",
    "        review_dict['rating'].append(review.find('div', class_='review_grade').find_all('div')[0].text)\n",
    "        if review.find('span', class_='blurb blurb_expanded'):\n",
    "            review_dict['review'].append(review.find('span', class_='blurb blurb_expanded').text)\n",
    "        else:\n",
    "            review_dict['review'].append(review.find('div', class_='review_body').find('span').text)\n",
    "\n",
    "sword_reviews = pd.DataFrame(review_dict)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
